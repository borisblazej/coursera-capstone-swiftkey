---
title: "Developing The Swiftkey1 Model"
author: "Boris Blazej"
date: '2022-05-01'
output: html_document
---

```{r setup, include=FALSE}
# Options
knitr::opts_chunk$set(echo = TRUE)

# Parameters
raw_text <- "../data/en_US.twitter.txt"

# Libraries
library(profvis)


# The "package" = needed functions
source("swiftkey1.R")
```

## Notes

 - Parameters: text quantity, top n words
 - Performance
    - Profile: build + predict
    - Size of model object
    - Precision (specificity, ...)
 
## Train / Build the model

```{r train}

# Parameters
param_text_lines <- 500000 # 100000-300000
param_top_ngrams <- 3000 # 5000, 3000, 1000 
param_n_gram <- 3 # 2,3,4


# training
set.seed(123)
# profvis({
   # sample_text <- load_text(raw_text, nrows = param_text_lines) 
# })
sample_text <- load_text(raw_text, nrows = param_text_lines)
train_index <- sample(1:length(sample_text), 
                      floor(0.9*length(sample_text)))
train_text <- sample_text[train_index]
test_text <- sample_text[-train_index]

# profvis({
    ngram_model <- train_model(train_text, param_n_gram, param_top_ngrams)
# })
    
next_word(ngram_model, "i thank you")
next_word(ngram_model, "It would mean the")
next_word(ngram_model, "i'm watching that ")

ngram_model[[4]] %>% 
    filter(X3 == "the", X2 == "mean")

```

```{r predict}

prediction_list(ngram_model, c("i", "thank", "you"))

```


```{r test}

# Prepare test data

test_data <- as.data.frame(str_replace_all(test_text, "\\s+", " "))
names(test_data) <- c("text")

test_data <- test_data %>% 
    mutate(n_words = str_count(text, "\\w\\s\\w") + 1) %>% 
    filter(n_words >= 4)

test_data$start_word <- round(runif(nrow(test_data),1,test_data$n_words -3))
 
test_data <- test_data %>% 
    mutate(regex1 = paste0("([\\w-']+\\s){",start_word-1,"}"),
           phrase1 = str_remove(text,regex1),
           phrase2 = str_extract(phrase1, "([\\w-']+\\s){3}[\\w-']+"),
           input_phrase = str_extract(phrase1, "([\\w-']+\\s){3}"),
           next_word = str_remove(phrase2,"([\\w-']+\\s){3}")) %>% 
    select(input_phrase, next_word)

# Do test and protocol

test_size <- 500
test_sample <- sample(1:nrow(test_data), test_size)
test_protocoll <- test_data[test_sample,]

for(i in 1:test_size) {
    test_protocoll$prediction[i] <- 
        next_word(ngram_model,test_protocoll$input_phrase[i])
}

test_protocoll %>% 
    mutate(correct = next_word == prediction) %>%
    summarize(performance = sum(correct, na.rm = T) / n())

```



```{r quiz week 4}


test <- prediction_list(ngram_model, last_n_words("When you breathe, I want to be the air for you. I'll be there for you, I'd live and I'd",3)) %>% 
    filter(word %in% c("die", "eat", "sleep", "give"))
prediction_list(ngram_model, last_n_words("Guy at my table's wife got up to go to the bathroom and I asked about dessert and he started telling me about his",3))
prediction_list(ngram_model, last_n_words("I'd give anything to see arctic monkeys this",3))
prediction_list(ngram_model, last_n_words("Talking to your mom has the same effect as a hug and helps reduce your",3))
test <- prediction_list(ngram_model, last_n_words("When you were in Holland you were like 1 inch away from me but you hadn't time to take a",3)) %>%
    filter(word %in% c("look", "minute", "walk", "picture"))
test <- prediction_list(ngram_model, last_n_words("I'd just like all of these questions answered, a presentation of evidence, and a jury to settle the",3))
prediction_list(ngram_model, last_n_words("I can't deal with unsymetrical things. I can't even hold an uneven number of bags of groceries in each",3))
prediction_list(ngram_model, "Every inch of you is perfect from the bottom to the")
prediction_list(ngram_model, "Iâ€™m thankful my childhood was filled with imagination and bruises from playing")
prediction_list(ngram_model, "I like how the same people are in almost all of Adam Sandler's")

```

